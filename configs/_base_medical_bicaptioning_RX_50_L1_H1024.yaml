# -----------------------------------------------------------------------------
# Base config: VirTex pretraining for our "base" bicaptioning model:
# ResNet-50 + (L = 1, H = 1024) transformer trained for 500K iterations.
# -----------------------------------------------------------------------------
RANDOM_SEED: 0
AMP: true
CUDNN_BENCHMARK: true
CUDNN_DETERMINISTIC: false

DATA:
  #ROOT: "/home/kouyoumin/hdd/A3/VGHK/data"
  ROOT: "/run/user/1000/gvfs/smb-share:server=172.16.16.254,share=datasets/Mammography/mammodata"
  CSV_PATH: "/home/kouyoumin/hdd/A3/VGHK/list.csv"
  TOKENIZER_MODEL: "virtex/data/datasets/vocab/mammo_3k.model"
  VOCAB_SIZE: 10000
  UNK_INDEX: 0
  SOS_INDEX: 1
  EOS_INDEX: 2
  MASK_INDEX: 3

  IMAGE_CROP_SIZE: 896
  MAX_CAPTION_LENGTH: 90

  IMAGE_TRANSFORM_TRAIN:
    - "resize"
    - "elastic"
    - "randomgamma"

  IMAGE_TRANSFORM_VAL:
    - "resize"

  USE_PERCENTAGE: 100.0
  USE_SINGLE_CAPTION: false

MODEL:
  NAME: "mammo"

  VISUAL:
    NAME: "torchvision::resnext50_32x4d"
    PRETRAINED: false
    FROZEN: false

  TEXTUAL:
    NAME: "transdec_postnorm::L1_H1024_A16_F4096"
    DROPOUT: 0.1

  DECODER:
    NAME: "beam_search"
    BEAM_SIZE: 5

OPTIM:
  OPTIMIZER_NAME: "sgd"
  SGD_MOMENTUM: 0.9
  WEIGHT_DECAY: 0.0001

  LOOKAHEAD:
    USE: true
    ALPHA: 0.5
    STEPS: 5

  BATCH_SIZE: 8
  CNN_LR: 0.01
  LR: 0.001
  NUM_ITERATIONS: 120000

  WARMUP_STEPS: 2000
  LR_DECAY_NAME: "cosine"

  NO_DECAY: ".*textual.(embedding|transformer).*(norm.*|bias)"
  CLIP_GRAD_NORM: 10.0

